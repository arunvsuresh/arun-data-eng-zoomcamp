{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "01b295bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.compute as pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3468eef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('taxi+_zone_lookup.csv')\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45557c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32d39745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/Cellar/apache-spark/3.4.0/libexec/python/pyspark/__init__.py'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03d6fe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.parquet('zones_test', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6bc24ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"LocationID\",\"Borough\",\"Zone\",\"service_zone\"\r",
      "\r\n",
      "1,\"EWR\",\"Newark Airport\",\"EWR\"\r",
      "\r\n",
      "2,\"Queens\",\"Jamaica Bay\",\"Boro Zone\"\r",
      "\r\n",
      "3,\"Bronx\",\"Allerton/Pelham Gardens\",\"Boro Zone\"\r",
      "\r\n",
      "4,\"Manhattan\",\"Alphabet City\",\"Yellow Zone\"\r",
      "\r\n",
      "5,\"Staten Island\",\"Arden Heights\",\"Boro Zone\"\r",
      "\r\n",
      "6,\"Staten Island\",\"Arrochar/Fort Wadsworth\",\"Boro Zone\"\r",
      "\r\n",
      "7,\"Queens\",\"Astoria\",\"Boro Zone\"\r",
      "\r\n",
      "8,\"Queens\",\"Astoria Park\",\"Boro Zone\"\r",
      "\r\n",
      "9,\"Queens\",\"Auburndale\",\"Boro Zone\"\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head taxi+_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7b848a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 72\r\n",
      "-rw-r--r--  1 arunsuresh  staff    16K Apr 27 10:07 Untitled.ipynb\r\n",
      "-rw-r--r--  1 arunsuresh  wheel    12K Aug 17  2016 taxi+_zone_lookup.csv\r\n",
      "-rw-r--r--  1 arunsuresh  wheel   2.1K Apr 27 10:15 test.ipynb\r\n",
      "drwxr-xr-x@ 6 arunsuresh  staff   192B Apr 27 10:16 \u001b[34mzones_test\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "638b7a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-04-27 10:18:16--  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-01.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 108.138.245.58, 108.138.245.96, 108.138.245.225, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|108.138.245.58|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 308924937 (295M) [application/x-www-form-urlencoded]\n",
      "Saving to: 'fhvhv_tripdata_2021-01.parquet'\n",
      "\n",
      "fhvhv_tripdata_2021 100%[===================>] 294.61M  2.26MB/s    in 2m 11s  \n",
      "\n",
      "2023-04-27 10:20:27 (2.25 MB/s) - 'fhvhv_tripdata_2021-01.parquet' saved [308924937/308924937]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-01.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2a4675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 1001 fhvhv_tripdata_2021-01.parquet > head.parquet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e33069f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pandas = \\\n",
    "# pq.read_table('fhvhv_tripdata_2021-01.parquet')\\\n",
    "# .to_pandas(safe=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "042ac688",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = \\\n",
    "pq.read_table(\"fhvhv_tripdata_2021-01.parquet\")\n",
    "\n",
    "df_pandas = table.filter(\n",
    "    pc.less_equal(table[\"dropoff_datetime\"],\n",
    "    pa.scalar(pd.Timestamp.max))\n",
    ").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1c0b4d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = df_pandas.iloc[:1001, ]\n",
    "# df_pandas = \\\n",
    "# df_pandas.loc[:, ['hvfhs_license_num', 'dispatching_base_num', 'pickup_datetime', 'dropoff_datetime', 'PULocationID', 'DOLocationID', 'shared_request_flag']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "93d56816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('hvfhs_license_num', StringType(), True), StructField('dispatching_base_num', StringType(), True), StructField('originating_base_num', StringType(), True), StructField('request_datetime', TimestampType(), True), StructField('on_scene_datetime', TimestampType(), True), StructField('pickup_datetime', TimestampType(), True), StructField('dropoff_datetime', TimestampType(), True), StructField('PULocationID', LongType(), True), StructField('DOLocationID', LongType(), True), StructField('trip_miles', DoubleType(), True), StructField('trip_time', LongType(), True), StructField('base_passenger_fare', DoubleType(), True), StructField('tolls', DoubleType(), True), StructField('bcf', DoubleType(), True), StructField('sales_tax', DoubleType(), True), StructField('congestion_surcharge', DoubleType(), True), StructField('airport_fee', DoubleType(), True), StructField('tips', DoubleType(), True), StructField('driver_pay', DoubleType(), True), StructField('shared_request_flag', StringType(), True), StructField('shared_match_flag', StringType(), True), StructField('access_a_ride_flag', StringType(), True), StructField('wav_request_flag', StringType(), True), StructField('wav_match_flag', StringType(), True)])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(df_pandas).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e29937c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9e11cdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType(\n",
    "    [\n",
    "        types.StructField('hvfhs_license_num', types.StringType(), True), types.StructField('dispatching_base_num', types.StringType(), True), types.StructField('originating_base_num', types.StringType(), True), types.StructField('request_datetime', types.TimestampType(), True), types.StructField('on_scene_datetime', types.TimestampType(), True), types.StructField('pickup_datetime', types.TimestampType(), True), types.StructField('dropoff_datetime', types.TimestampType(), True), types.StructField('PULocationID', types.LongType(), True), types.StructField('DOLocationID', types.LongType(), True), types.StructField('trip_miles', types.DoubleType(), True), types.StructField('trip_time', types.LongType(), True), types.StructField('base_passenger_fare', types.DoubleType(), True), types.StructField('tolls', types.DoubleType(), True), types.StructField('bcf', types.DoubleType(), True), types.StructField('sales_tax', types.DoubleType(), True), types.StructField('congestion_surcharge', types.DoubleType(), True), types.StructField('airport_fee', types.DoubleType(), True), types.StructField('tips', types.DoubleType(), True), types.StructField('driver_pay', types.DoubleType(), True), types.StructField('shared_request_flag', types.StringType(), True), types.StructField('shared_match_flag', types.StringType(), True), types.StructField('access_a_ride_flag', types.StringType(), True), types.StructField('wav_request_flag', types.StringType(), True), types.StructField('wav_match_flag', types.StringType(), True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6769fbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = spark.read \\\n",
    "#     .schema(schema) \\\n",
    "#     .csv('fhvhv_tripdata_2021-01.csv')\n",
    "\n",
    "df = spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .parquet('fhvhv_tripdata_2021-01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "432f383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "64a76b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1b455d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "726b08fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_ALREADY_EXISTS] Path file:/Users/arunsuresh/Documents/arun-data-eng-zoomcamp/week_5/code/notebooks/fhvhv/2021/01 already exists. Set mode as \"overwrite\" to overwrite the existing path.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfhvhv/2021/01\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.4.0/libexec/python/pyspark/sql/readwriter.py:1656\u001b[0m, in \u001b[0;36mDataFrameWriter.parquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartitionBy(partitionBy)\n\u001b[1;32m   1655\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(compression\u001b[38;5;241m=\u001b[39mcompression)\n\u001b[0;32m-> 1656\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.4.0/libexec/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.4.0/libexec/python/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [PATH_ALREADY_EXISTS] Path file:/Users/arunsuresh/Documents/arun-data-eng-zoomcamp/week_5/code/notebooks/fhvhv/2021/01 already exists. Set mode as \"overwrite\" to overwrite the existing path."
     ]
    }
   ],
   "source": [
    "# df.write.parquet('fhvhv/2021/01', mode='overwrite')\n",
    "\n",
    "df.write.parquet('fhvhv/2021/01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e6cdc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
