{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8e367dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.compute as pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cbd8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('taxi+_zone_lookup.csv')\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45557c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32d39745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/Cellar/apache-spark/3.4.0/libexec/python/pyspark/__init__.py'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03d6fe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.parquet('zones_test', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6bc24ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"LocationID\",\"Borough\",\"Zone\",\"service_zone\"\r",
      "\r\n",
      "1,\"EWR\",\"Newark Airport\",\"EWR\"\r",
      "\r\n",
      "2,\"Queens\",\"Jamaica Bay\",\"Boro Zone\"\r",
      "\r\n",
      "3,\"Bronx\",\"Allerton/Pelham Gardens\",\"Boro Zone\"\r",
      "\r\n",
      "4,\"Manhattan\",\"Alphabet City\",\"Yellow Zone\"\r",
      "\r\n",
      "5,\"Staten Island\",\"Arden Heights\",\"Boro Zone\"\r",
      "\r\n",
      "6,\"Staten Island\",\"Arrochar/Fort Wadsworth\",\"Boro Zone\"\r",
      "\r\n",
      "7,\"Queens\",\"Astoria\",\"Boro Zone\"\r",
      "\r\n",
      "8,\"Queens\",\"Astoria Park\",\"Boro Zone\"\r",
      "\r\n",
      "9,\"Queens\",\"Auburndale\",\"Boro Zone\"\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head taxi+_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7b848a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 72\r\n",
      "-rw-r--r--  1 arunsuresh  staff    16K Apr 27 10:07 Untitled.ipynb\r\n",
      "-rw-r--r--  1 arunsuresh  wheel    12K Aug 17  2016 taxi+_zone_lookup.csv\r\n",
      "-rw-r--r--  1 arunsuresh  wheel   2.1K Apr 27 10:15 test.ipynb\r\n",
      "drwxr-xr-x@ 6 arunsuresh  staff   192B Apr 27 10:16 \u001b[34mzones_test\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "638b7a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-04-27 10:18:16--  https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-01.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 108.138.245.58, 108.138.245.96, 108.138.245.225, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|108.138.245.58|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 308924937 (295M) [application/x-www-form-urlencoded]\n",
      "Saving to: 'fhvhv_tripdata_2021-01.parquet'\n",
      "\n",
      "fhvhv_tripdata_2021 100%[===================>] 294.61M  2.26MB/s    in 2m 11s  \n",
      "\n",
      "2023-04-27 10:20:27 (2.25 MB/s) - 'fhvhv_tripdata_2021-01.parquet' saved [308924937/308924937]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-01.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8227add0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 1001 fhvhv_tripdata_2021-01.parquet > head.parquet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5d6f0db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pandas = \\\n",
    "# pq.read_table('fhvhv_tripdata_2021-01.parquet')\\\n",
    "# .to_pandas(safe=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ed68485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = \\\n",
    "pq.read_table(\"fhvhv_tripdata_2021-01.parquet\")\n",
    "\n",
    "df_pandas = table.filter(\n",
    "    pc.less_equal(table[\"dropoff_datetime\"],\n",
    "    pa.scalar(pd.Timestamp.max))\n",
    ").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "58df38c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = df_pandas.iloc[:1001, ]\n",
    "# df_pandas = \\\n",
    "# df_pandas.loc[:, ['hvfhs_license_num', 'dispatching_base_num', 'pickup_datetime', 'dropoff_datetime', 'PULocationID', 'DOLocationID', 'shared_request_flag']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e779d2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('hvfhs_license_num', StringType(), True), StructField('dispatching_base_num', StringType(), True), StructField('originating_base_num', StringType(), True), StructField('request_datetime', TimestampType(), True), StructField('on_scene_datetime', TimestampType(), True), StructField('pickup_datetime', TimestampType(), True), StructField('dropoff_datetime', TimestampType(), True), StructField('PULocationID', LongType(), True), StructField('DOLocationID', LongType(), True), StructField('trip_miles', DoubleType(), True), StructField('trip_time', LongType(), True), StructField('base_passenger_fare', DoubleType(), True), StructField('tolls', DoubleType(), True), StructField('bcf', DoubleType(), True), StructField('sales_tax', DoubleType(), True), StructField('congestion_surcharge', DoubleType(), True), StructField('airport_fee', DoubleType(), True), StructField('tips', DoubleType(), True), StructField('driver_pay', DoubleType(), True), StructField('shared_request_flag', StringType(), True), StructField('shared_match_flag', StringType(), True), StructField('access_a_ride_flag', StringType(), True), StructField('wav_request_flag', StringType(), True), StructField('wav_match_flag', StringType(), True)])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(df_pandas).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7351d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9e93c8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType(\n",
    "    [\n",
    "        types.StructField('hvfhs_license_num', types.StringType(), True), types.StructField('dispatching_base_num', types.StringType(), True), types.StructField('originating_base_num', types.StringType(), True), types.StructField('request_datetime', types.TimestampType(), True), types.StructField('on_scene_datetime', types.TimestampType(), True), types.StructField('pickup_datetime', types.TimestampType(), True), types.StructField('dropoff_datetime', types.TimestampType(), True), types.StructField('PULocationID', types.LongType(), True), types.StructField('DOLocationID', types.LongType(), True), types.StructField('trip_miles', types.DoubleType(), True), types.StructField('trip_time', types.LongType(), True), types.StructField('base_passenger_fare', types.DoubleType(), True), types.StructField('tolls', types.DoubleType(), True), types.StructField('bcf', types.DoubleType(), True), types.StructField('sales_tax', types.DoubleType(), True), types.StructField('congestion_surcharge', types.DoubleType(), True), types.StructField('airport_fee', types.DoubleType(), True), types.StructField('tips', types.DoubleType(), True), types.StructField('driver_pay', types.DoubleType(), True), types.StructField('shared_request_flag', types.StringType(), True), types.StructField('shared_match_flag', types.StringType(), True), types.StructField('access_a_ride_flag', types.StringType(), True), types.StructField('wav_request_flag', types.StringType(), True), types.StructField('wav_match_flag', types.StringType(), True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d0f76458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = spark.read \\\n",
    "#     .schema(schema) \\\n",
    "#     .csv('fhvhv_tripdata_2021-01.csv')\n",
    "\n",
    "df = spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .parquet('fhvhv_tripdata_2021-01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "338565e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3ef40447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d7afbe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "410509b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_ALREADY_EXISTS] Path file:/Users/arunsuresh/Documents/arun-data-eng-zoomcamp/week_5/code/notebooks/fhvhv/2021/01 already exists. Set mode as \"overwrite\" to overwrite the existing path.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfhvhv/2021/01\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.4.0/libexec/python/pyspark/sql/readwriter.py:1656\u001b[0m, in \u001b[0;36mDataFrameWriter.parquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartitionBy(partitionBy)\n\u001b[1;32m   1655\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(compression\u001b[38;5;241m=\u001b[39mcompression)\n\u001b[0;32m-> 1656\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.4.0/libexec/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.4.0/libexec/python/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [PATH_ALREADY_EXISTS] Path file:/Users/arunsuresh/Documents/arun-data-eng-zoomcamp/week_5/code/notebooks/fhvhv/2021/01 already exists. Set mode as \"overwrite\" to overwrite the existing path."
     ]
    }
   ],
   "source": [
    "# df.write.parquet('fhvhv/2021/01', mode='overwrite')\n",
    "\n",
    "df.write.parquet('fhvhv/2021/01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d60308bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet('files/fhvhv/2021/01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5f186dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- originating_base_num: string (nullable = true)\n",
      " |-- request_datetime: timestamp (nullable = true)\n",
      " |-- on_scene_datetime: timestamp (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- trip_miles: double (nullable = true)\n",
      " |-- trip_time: long (nullable = true)\n",
      " |-- base_passenger_fare: double (nullable = true)\n",
      " |-- tolls: double (nullable = true)\n",
      " |-- bcf: double (nullable = true)\n",
      " |-- sales_tax: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      " |-- tips: double (nullable = true)\n",
      " |-- driver_pay: double (nullable = true)\n",
      " |-- shared_request_flag: string (nullable = true)\n",
      " |-- shared_match_flag: string (nullable = true)\n",
      " |-- access_a_ride_flag: string (nullable = true)\n",
      " |-- wav_request_flag: string (nullable = true)\n",
      " |-- wav_match_flag: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2d4b0cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3b6ef558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e5a8af90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crazy_stuff(base_num):\n",
    "    num = int(base_num[1:])\n",
    "    if num % 7 == 0:\n",
    "        return f's/{num:03x}'\n",
    "    else:\n",
    "        return f'e/{num:03x}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "46255365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s/b44'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crazy_stuff('B02884')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5b0dc8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "crazy_stuff_udf = \\\n",
    "F.udf(crazy_stuff, returnType=types.StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cd794c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 27:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------------+------------+------------+\n",
      "|base_id|pickup_date|dropoff_date|PULocationID|DOLocationID|\n",
      "+-------+-----------+------------+------------+------------+\n",
      "|  e/acc| 2021-01-11|  2021-01-11|         262|         231|\n",
      "|  e/a39| 2021-01-05|  2021-01-05|          61|         181|\n",
      "|  e/9ce| 2021-01-02|  2021-01-02|         100|           1|\n",
      "|  e/b42| 2021-01-31|  2021-01-31|         232|           4|\n",
      "|  s/af0| 2021-01-05|  2021-01-05|         162|           1|\n",
      "|  e/b43| 2021-01-27|  2021-01-27|          68|          68|\n",
      "|  e/9ce| 2021-01-17|  2021-01-17|         205|         205|\n",
      "|  e/b35| 2021-01-30|  2021-01-30|         256|         255|\n",
      "|  e/b3b| 2021-01-15|  2021-01-15|          89|          91|\n",
      "|  e/9ce| 2021-01-04|  2021-01-04|         132|         102|\n",
      "|  e/acc| 2021-01-11|  2021-01-11|          97|          61|\n",
      "|  e/9ce| 2021-01-21|  2021-01-21|          79|          37|\n",
      "|  e/b32| 2021-01-02|  2021-01-03|          26|         178|\n",
      "|  e/b49| 2021-01-14|  2021-01-14|         181|         198|\n",
      "|  e/acc| 2021-01-08|  2021-01-08|          76|          91|\n",
      "|  e/b3c| 2021-01-15|  2021-01-15|         246|          16|\n",
      "|  s/b36| 2021-01-27|  2021-01-27|         135|          73|\n",
      "|  e/9ce| 2021-01-18|  2021-01-18|          74|         234|\n",
      "|  e/a39| 2021-01-11|  2021-01-11|          68|         211|\n",
      "|  e/b3f| 2021-01-24|  2021-01-24|         249|         236|\n",
      "+-------+-----------+------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df \\\n",
    ".withColumn('pickup_date', F.to_date(df.pickup_datetime))\\\n",
    ".withColumn('dropoff_date', F.to_date(df.dropoff_datetime))\\\n",
    ".withColumn('base_id', crazy_stuff_udf(df.dispatching_base_num))\\\n",
    ".select('base_id',\\\n",
    "       'pickup_date', \\\n",
    "       'dropoff_date',\\\n",
    "       'PULocationID', \\\n",
    "       'DOLocationID')\\\n",
    ".show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3fbcd27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(pickup_datetime=datetime.datetime(2021, 1, 11, 10, 40, 22), dropoff_datetime=datetime.datetime(2021, 1, 11, 11, 15, 49), PULocationID=262, DOLocationID=231),\n",
       " Row(pickup_datetime=datetime.datetime(2021, 1, 5, 7, 13, 22), dropoff_datetime=datetime.datetime(2021, 1, 5, 7, 27, 50), PULocationID=61, DOLocationID=181),\n",
       " Row(pickup_datetime=datetime.datetime(2021, 1, 31, 10, 42, 9), dropoff_datetime=datetime.datetime(2021, 1, 31, 10, 59, 52), PULocationID=232, DOLocationID=4),\n",
       " Row(pickup_datetime=datetime.datetime(2021, 1, 27, 14, 24, 36), dropoff_datetime=datetime.datetime(2021, 1, 27, 14, 26, 43), PULocationID=68, DOLocationID=68),\n",
       " Row(pickup_datetime=datetime.datetime(2021, 1, 30, 0, 35, 46), dropoff_datetime=datetime.datetime(2021, 1, 30, 0, 39, 42), PULocationID=256, DOLocationID=255)]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.\\\n",
    "select('pickup_datetime', \\\n",
    "       'dropoff_datetime',\\\n",
    "       'PULocationID', \\\n",
    "       'DOLocationID').filter(df.hvfhs_license_num == 'HV0003') \\\n",
    ".head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72397c25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
